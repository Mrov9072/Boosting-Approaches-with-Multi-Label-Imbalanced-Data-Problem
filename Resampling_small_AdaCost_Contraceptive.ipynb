{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class distribution:\n",
      "target\n",
      "1    629\n",
      "3    511\n",
      "2    333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after under-sampling:\n",
      "target\n",
      "1    333\n",
      "2    333\n",
      "3    333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after over-sampling:\n",
      "target\n",
      "1    629\n",
      "2    629\n",
      "3    629\n",
      "Name: count, dtype: int64\n",
      "Y_Ros: (1887, 1), Y_Rus: (999, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from data_download import *\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from utils import *\n",
    "import warnings\n",
    "from adacost import AdaCost\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "warnings. filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Generate a synthetic imbalanced dataset\n",
    "data = fetch_ucirepo(id=30)\n",
    "X,y = data.data.features, data.data.targets\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "# Display the imbalance\n",
    "print(\"Initial class distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "# Step 2: Apply Random Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "# Convert the results back to a DataFrame\n",
    "df_rus = pd.DataFrame(X_rus)\n",
    "df_rus['target'] = y_rus\n",
    "\n",
    "# Step 3: Apply Random Over-sampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "# Convert the results back to a DataFrame\n",
    "df_ros = pd.DataFrame(X_ros)\n",
    "df_ros['target'] = y_ros\n",
    "\n",
    "# Print the class distributions after resampling\n",
    "print(\"\\nClass distribution after under-sampling:\")\n",
    "print(df_rus['target'].value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after over-sampling:\")\n",
    "print(df_ros['target'].value_counts())\n",
    "print(f\"Y_Ros: {y_ros.shape}, Y_Rus: {y_rus.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1509, 9),(1509, 1),(799, 9),(799, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_ros,X_test_ros,y_train_ros,y_test_ros  = train_test_split(X_ros,y_ros,test_size=0.2,random_state=42)\n",
    "X_train_rus,X_test_rus,y_train_rus,y_test_rus  = train_test_split(X_rus,y_rus,test_size=0.2,random_state=42)\n",
    "print(f\"{X_train_ros.shape},{y_train_ros.shape},{X_train_rus.shape},{y_train_rus.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaclassifier_ros = AdaBoostClassifier(random_state=42)\n",
    "grboostclassifier_ros = GradientBoostingClassifier(random_state=42)\n",
    "adaclassifier_ros.fit(X_train_ros,y_train_ros)\n",
    "grboostclassifier_ros.fit(X_train_ros,y_train_ros)\n",
    "y_pred_adaboost_ros = adaclassifier_ros.predict(X_test_ros)\n",
    "y_pred_grboost_ros = grboostclassifier_ros.predict(X_test_ros)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Metrics:\n",
      "Accuracy: 0.5502645502645502\n",
      "Precision: 0.5558788795759174\n",
      "Recall: 0.5502645502645502\n",
      "Weighted F1 Score: 0.5516795246554543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.59      0.60       115\n",
      "           2       0.58      0.52      0.55       141\n",
      "           3       0.47      0.54      0.50       122\n",
      "\n",
      "    accuracy                           0.55       378\n",
      "   macro avg       0.56      0.55      0.55       378\n",
      "weighted avg       0.56      0.55      0.55       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_adaboost_ros = accuracy_score(y_test_ros, y_pred_adaboost_ros)\n",
    "precision_adaboost_ros = precision_score(y_test_ros, y_pred_adaboost_ros, average='weighted')\n",
    "recall_adaboost_ros = recall_score(y_test_ros, y_pred_adaboost_ros, average='weighted')\n",
    "f1_adaboost_ros = f1_score(y_test_ros, y_pred_adaboost_ros, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost with oversampling dataset\n",
    "print(\"AdaBoost Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_adaboost_ros)\n",
    "print(\"Precision:\", precision_adaboost_ros)\n",
    "print(\"Recall:\", recall_adaboost_ros)\n",
    "print(\"Weighted F1 Score:\", f1_adaboost_ros)\n",
    "print(classification_report(y_true=y_test_ros,y_pred=y_pred_adaboost_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Metrics:\n",
      "Accuracy: 0.6190476190476191\n",
      "Precision: 0.6300747418944698\n",
      "Recall: 0.6190476190476191\n",
      "Weighted F1 Score: 0.621287425915189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.62      0.63       115\n",
      "           2       0.71      0.60      0.65       141\n",
      "           3       0.53      0.64      0.58       122\n",
      "\n",
      "    accuracy                           0.62       378\n",
      "   macro avg       0.63      0.62      0.62       378\n",
      "weighted avg       0.63      0.62      0.62       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_grboost_ros = accuracy_score(y_test_ros, y_pred_grboost_ros)\n",
    "precision_grboost_ros = precision_score(y_test_ros, y_pred_grboost_ros, average='weighted')\n",
    "recall_grboost_ros = recall_score(y_test_ros, y_pred_grboost_ros, average='weighted')\n",
    "f1_grboost_ros = f1_score(y_test_ros, y_pred_grboost_ros, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost\n",
    "print(\"AdaBoost Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_grboost_ros)\n",
    "print(\"Precision:\", precision_grboost_ros)\n",
    "print(\"Recall:\", recall_grboost_ros)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_ros)\n",
    "print(classification_report(y_true=y_test_ros,y_pred=y_pred_grboost_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaclassifier_rus = AdaBoostClassifier(random_state=42)\n",
    "grboostclassifier_rus = GradientBoostingClassifier(random_state=42)\n",
    "adaclassifier_rus.fit(X_train_rus,y_train_rus)\n",
    "grboostclassifier_rus.fit(X_train_rus,y_train_rus)\n",
    "y_pred_adaboost_rus = adaclassifier_ros.predict(X_test_rus)\n",
    "y_pred_grboost_rus = grboostclassifier_ros.predict(X_test_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Metrics wit RUS:\n",
      "Accuracy: 0.55\n",
      "Precision: 0.5577659266409265\n",
      "Recall: 0.55\n",
      "Weighted F1 Score: 0.5514550480506369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.55      0.60        67\n",
      "           2       0.53      0.60      0.56        65\n",
      "           3       0.49      0.50      0.49        68\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.56      0.55      0.55       200\n",
      "weighted avg       0.56      0.55      0.55       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_adaboost_rus = accuracy_score(y_test_rus, y_pred_adaboost_rus)\n",
    "precision_adaboost_rus = precision_score(y_test_rus, y_pred_adaboost_rus, average='weighted')\n",
    "recall_adaboost_rus = recall_score(y_test_rus, y_pred_adaboost_rus, average='weighted')\n",
    "f1_adaboost_rus = f1_score(y_test_rus, y_pred_adaboost_rus, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost\n",
    "print(\"AdaBoost Classifier Metrics wit RUS:\")\n",
    "print(\"Accuracy:\", accuracy_adaboost_rus)\n",
    "print(\"Precision:\", precision_adaboost_rus)\n",
    "print(\"Recall:\", recall_adaboost_rus)\n",
    "print(\"Weighted F1 Score:\", f1_adaboost_rus)\n",
    "print(classification_report(y_true=y_test_rus,y_pred=y_pred_adaboost_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Classifier Metrics with RUS:\n",
      "Accuracy: 0.59\n",
      "Precision: 0.6002123689727463\n",
      "Recall: 0.59\n",
      "Weighted F1 Score: 0.5912865133649805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.55      0.62        67\n",
      "           2       0.61      0.68      0.64        65\n",
      "           3       0.49      0.54      0.52        68\n",
      "\n",
      "    accuracy                           0.59       200\n",
      "   macro avg       0.60      0.59      0.59       200\n",
      "weighted avg       0.60      0.59      0.59       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_grboost_rus = accuracy_score(y_test_rus, y_pred_grboost_rus)\n",
    "precision_grboost_rus = precision_score(y_test_rus, y_pred_grboost_rus, average='weighted')\n",
    "recall_grboost_rus = recall_score(y_test_rus, y_pred_grboost_rus, average='weighted')\n",
    "f1_grboost_rus = f1_score(y_test_rus, y_pred_grboost_rus, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost\n",
    "print(\"GradientBoost Classifier Metrics with RUS:\")\n",
    "print(\"Accuracy:\", accuracy_grboost_rus)\n",
    "print(\"Precision:\", precision_grboost_rus)\n",
    "print(\"Recall:\", recall_grboost_rus)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_rus)\n",
    "print(classification_report(y_true=y_test_rus,y_pred=y_pred_grboost_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17562720252593492"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(y_test_ros,adaclassifier_ros.predict_proba(X_test_ros),num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaCost(learning_rate=0.01, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ada = AdaCost(algorithm = \"SAMME.R\",random_state = 100)\n",
    "cv = GridSearchCV(ada,\n",
    "                  param_grid = {'learning_rate':[0.01,0.05,0.1,0.25,0.5,1],'n_estimators':[10,20,50,100,200]},\n",
    "                  verbose = 1, \n",
    "                  n_jobs = 1)\n",
    "cv.fit(X_train_ros,y_train_ros)\n",
    "cv.best_params_,cv.best_score_\n",
    "ada_cv = cv.best_estimator_\n",
    "print(cv.best_estimator_)\n",
    "y_pred = ada_cv.predict(X_test_ros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaCost Classifier Metrics with RUS:\n",
      "Accuracy: 0.46825396825396826\n",
      "Precision: 0.33721538235427123\n",
      "Recall: 0.46825396825396826\n",
      "Weighted F1 Score: 0.3811501054450836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.82      0.54       115\n",
      "           2       0.58      0.59      0.58       141\n",
      "           3       0.00      0.00      0.00       122\n",
      "\n",
      "    accuracy                           0.47       378\n",
      "   macro avg       0.33      0.47      0.37       378\n",
      "weighted avg       0.34      0.47      0.38       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_acost_ros = accuracy_score(y_test_ros, y_pred)\n",
    "precision_acost_ros = precision_score(y_test_ros, y_pred, average='weighted')\n",
    "recall_acost_ros = recall_score(y_test_ros, y_pred, average='weighted')\n",
    "f1_acost_ros = f1_score(y_test_ros, y_pred, average='weighted')\n",
    "print(\"AdaCost Classifier Metrics with RUS:\")\n",
    "print(\"Accuracy:\", accuracy_acost_ros)\n",
    "print(\"Precision:\", precision_acost_ros)\n",
    "print(\"Recall:\", recall_acost_ros)\n",
    "print(\"Weighted F1 Score:\", f1_acost_ros)\n",
    "print(classification_report(y_true=y_test_ros,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "AdaCost(learning_rate=0.01, random_state=100)\n",
      "AdaCost Classifier Metrics with RUS:\n",
      "Accuracy: 0.475\n",
      "Precision: 0.3134958495849585\n",
      "Recall: 0.59\n",
      "Weighted F1 Score: 0.5912865133649805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.70      0.57        67\n",
      "           2       0.48      0.74      0.58        65\n",
      "           3       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.32      0.48      0.38       200\n",
      "weighted avg       0.31      0.47      0.38       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ada_rus = AdaCost(algorithm = \"SAMME.R\",random_state = 100)\n",
    "cv = GridSearchCV(ada_rus,\n",
    "                  param_grid = {'learning_rate':[0.01,0.05,0.1,0.25,0.5,1],'n_estimators':[10,20,50,100,200]},\n",
    "                  verbose = 1, \n",
    "                  n_jobs = 1)\n",
    "cv.fit(X_train_rus,y_train_rus)\n",
    "cv.best_params_,cv.best_score_\n",
    "ada_cv = cv.best_estimator_\n",
    "print(cv.best_estimator_)\n",
    "y_pred_acost_rus = ada_cv.predict(X_test_rus)\n",
    "accuracy_acost_rus = accuracy_score(y_test_rus, y_pred_acost_rus)\n",
    "precision_acost_rus = precision_score(y_test_rus, y_pred_acost_rus, average='weighted')\n",
    "recall_acost_rus = recall_score(y_test_rus, y_pred_acost_rus, average='weighted')\n",
    "f1_acost_ros = f1_score(y_test_rus, y_pred_acost_rus, average='weighted')\n",
    "print(\"AdaCost Classifier Metrics with RUS:\")\n",
    "print(\"Accuracy:\", accuracy_acost_rus)\n",
    "print(\"Precision:\", precision_acost_rus)\n",
    "print(\"Recall:\", recall_grboost_rus)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_rus)\n",
    "print(classification_report(y_true=y_test_rus,y_pred=y_pred_acost_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@K: 0.2958\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "k = 50  # Consider the top-2 predictions\n",
    "\n",
    "# Calculate MAP@K\n",
    "mapk_score = mapk(y_test_rus.to_numpy().T[0,:], ada_cv.predict_proba(X_test_rus), 50)\n",
    "print(f\"MAP@K: {mapk_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
