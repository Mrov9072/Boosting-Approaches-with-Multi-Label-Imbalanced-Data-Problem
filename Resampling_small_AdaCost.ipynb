{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class distribution:\n",
      "target\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after under-sampling:\n",
      "target\n",
      "1    48\n",
      "2    48\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after over-sampling:\n",
      "target\n",
      "1    71\n",
      "2    71\n",
      "3    71\n",
      "Name: count, dtype: int64\n",
      "Y_Ros: (213, 1), Y_Rus: (144, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from data_download import *\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from utils import *\n",
    "import warnings\n",
    "from adacost import AdaCost\n",
    "warnings. filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Generate a synthetic imbalanced dataset\n",
    "X, y = download_data(filename='wine')\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "# Display the imbalance\n",
    "print(\"Initial class distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "# Step 2: Apply Random Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "# Convert the results back to a DataFrame\n",
    "df_rus = pd.DataFrame(X_rus)\n",
    "df_rus['target'] = y_rus\n",
    "\n",
    "# Step 3: Apply Random Over-sampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "# Convert the results back to a DataFrame\n",
    "df_ros = pd.DataFrame(X_ros)\n",
    "df_ros['target'] = y_ros\n",
    "\n",
    "# Print the class distributions after resampling\n",
    "print(\"\\nClass distribution after under-sampling:\")\n",
    "print(df_rus['target'].value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after over-sampling:\")\n",
    "print(df_ros['target'].value_counts())\n",
    "print(f\"Y_Ros: {y_ros.shape}, Y_Rus: {y_rus.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 13),(170, 1),(115, 13),(115, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_ros,X_test_ros,y_train_ros,y_test_ros  = train_test_split(X_ros,y_ros,test_size=0.2,random_state=42)\n",
    "X_train_rus,X_test_rus,y_train_rus,y_test_rus  = train_test_split(X_rus,y_rus,test_size=0.2,random_state=42)\n",
    "print(f\"{X_train_ros.shape},{y_train_ros.shape},{X_train_rus.shape},{y_train_rus.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaclassifier_ros = AdaBoostClassifier(random_state=42)\n",
    "grboostclassifier_ros = GradientBoostingClassifier(random_state=42)\n",
    "adaclassifier_ros.fit(X_train_ros,y_train_ros)\n",
    "grboostclassifier_ros.fit(X_train_ros,y_train_ros)\n",
    "y_pred_adaboost_ros = adaclassifier_ros.predict(X_test_ros)\n",
    "y_pred_grboost_ros = grboostclassifier_ros.predict(X_test_ros)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Metrics:\n",
      "Accuracy: 0.9302325581395349\n",
      "Precision: 0.9425444596443229\n",
      "Recall: 0.9302325581395349\n",
      "Weighted F1 Score: 0.930950594791555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.82      0.90        11\n",
      "           2       0.82      1.00      0.90        14\n",
      "           3       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.93        43\n",
      "   macro avg       0.94      0.92      0.92        43\n",
      "weighted avg       0.94      0.93      0.93        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_adaboost_ros = accuracy_score(y_test_ros, y_pred_adaboost_ros)\n",
    "precision_adaboost_ros = precision_score(y_test_ros, y_pred_adaboost_ros, average='weighted')\n",
    "recall_adaboost_ros = recall_score(y_test_ros, y_pred_adaboost_ros, average='weighted')\n",
    "f1_adaboost_ros = f1_score(y_test_ros, y_pred_adaboost_ros, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost with oversampling dataset\n",
    "print(\"AdaBoost Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_adaboost_ros)\n",
    "print(\"Precision:\", precision_adaboost_ros)\n",
    "print(\"Recall:\", recall_adaboost_ros)\n",
    "print(\"Weighted F1 Score:\", f1_adaboost_ros)\n",
    "print(classification_report(y_true=y_test_ros,y_pred=y_pred_adaboost_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Metrics:\n",
      "Accuracy: 0.9767441860465116\n",
      "Precision: 0.9786821705426355\n",
      "Recall: 0.9767441860465116\n",
      "Weighted F1 Score: 0.9768190839980526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.93      0.96        14\n",
      "           3       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           0.98        43\n",
      "   macro avg       0.97      0.98      0.97        43\n",
      "weighted avg       0.98      0.98      0.98        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_grboost_ros = accuracy_score(y_test_ros, y_pred_grboost_ros)\n",
    "precision_grboost_ros = precision_score(y_test_ros, y_pred_grboost_ros, average='weighted')\n",
    "recall_grboost_ros = recall_score(y_test_ros, y_pred_grboost_ros, average='weighted')\n",
    "f1_grboost_ros = f1_score(y_test_ros, y_pred_grboost_ros, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost\n",
    "print(\"AdaBoost Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_grboost_ros)\n",
    "print(\"Precision:\", precision_grboost_ros)\n",
    "print(\"Recall:\", recall_grboost_ros)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_ros)\n",
    "print(classification_report(y_true=y_test_ros,y_pred=y_pred_grboost_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaclassifier_rus = AdaBoostClassifier(random_state=42)\n",
    "grboostclassifier_rus = GradientBoostingClassifier(random_state=42)\n",
    "adaclassifier_rus.fit(X_train_rus,y_train_rus)\n",
    "grboostclassifier_rus.fit(X_train_rus,y_train_rus)\n",
    "y_pred_adaboost_rus = adaclassifier_ros.predict(X_test_rus)\n",
    "y_pred_grboost_rus = grboostclassifier_ros.predict(X_test_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Metrics wit RUS:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Weighted F1 Score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_adaboost_rus = accuracy_score(y_test_rus, y_pred_adaboost_rus)\n",
    "precision_adaboost_rus = precision_score(y_test_rus, y_pred_adaboost_rus, average='weighted')\n",
    "recall_adaboost_rus = recall_score(y_test_rus, y_pred_adaboost_rus, average='weighted')\n",
    "f1_adaboost_rus = f1_score(y_test_rus, y_pred_adaboost_rus, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost\n",
    "print(\"AdaBoost Classifier Metrics wit RUS:\")\n",
    "print(\"Accuracy:\", accuracy_adaboost_rus)\n",
    "print(\"Precision:\", precision_adaboost_rus)\n",
    "print(\"Recall:\", recall_adaboost_rus)\n",
    "print(\"Weighted F1 Score:\", f1_adaboost_rus)\n",
    "print(classification_report(y_true=y_test_rus,y_pred=y_pred_adaboost_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Classifier Metrics with RUS:\n",
      "Accuracy: 0.9655172413793104\n",
      "Precision: 0.9689655172413794\n",
      "Recall: 0.9655172413793104\n",
      "Weighted F1 Score: 0.9656036643332468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.97        29\n",
      "   macro avg       0.97      0.97      0.97        29\n",
      "weighted avg       0.97      0.97      0.97        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_grboost_rus = accuracy_score(y_test_rus, y_pred_grboost_rus)\n",
    "precision_grboost_rus = precision_score(y_test_rus, y_pred_grboost_rus, average='weighted')\n",
    "recall_grboost_rus = recall_score(y_test_rus, y_pred_grboost_rus, average='weighted')\n",
    "f1_grboost_rus = f1_score(y_test_rus, y_pred_grboost_rus, average='weighted')\n",
    "\n",
    "# Print the metrics for AdaBoost\n",
    "print(\"GradientBoost Classifier Metrics with RUS:\")\n",
    "print(\"Accuracy:\", accuracy_grboost_rus)\n",
    "print(\"Precision:\", precision_grboost_rus)\n",
    "print(\"Recall:\", recall_grboost_rus)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_rus)\n",
    "print(classification_report(y_true=y_test_rus,y_pred=y_pred_grboost_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20818377201733637"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(y_test_ros,adaclassifier_ros.predict_proba(X_test_ros),num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "AdaCost(learning_rate=0.01, n_estimators=100, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ada = AdaCost(algorithm = \"SAMME.R\",random_state = 100)\n",
    "cv = GridSearchCV(ada,\n",
    "                  param_grid = {'learning_rate':[0.01,0.05,0.1,0.25,0.5,1],'n_estimators':[10,20,50,100,200]},\n",
    "                  verbose = 1, \n",
    "                  n_jobs = 1)\n",
    "cv.fit(X_train_ros,y_train_ros)\n",
    "cv.best_params_,cv.best_score_\n",
    "ada_cv = cv.best_estimator_\n",
    "print(cv.best_estimator_)\n",
    "y_pred = ada_cv.predict(X_test_ros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaCost Classifier Metrics with RUS:\n",
      "Accuracy: 0.8372093023255814\n",
      "Precision: 0.8758669930640555\n",
      "Recall: 0.9767441860465116\n",
      "Weighted F1 Score: 0.9768190839980526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       0.68      0.93      0.79        14\n",
      "           3       1.00      0.67      0.80        18\n",
      "\n",
      "    accuracy                           0.84        43\n",
      "   macro avg       0.87      0.87      0.85        43\n",
      "weighted avg       0.88      0.84      0.84        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_acost_ros = accuracy_score(y_test_ros, y_pred)\n",
    "precision_acost_ros = precision_score(y_test_ros, y_pred, average='weighted')\n",
    "recall_acost_ros = recall_score(y_test_ros, y_pred, average='weighted')\n",
    "f1_acost_ros = f1_score(y_test_ros, y_pred, average='weighted')\n",
    "print(\"AdaCost Classifier Metrics with RUS:\")\n",
    "print(\"Accuracy:\", accuracy_acost_ros)\n",
    "print(\"Precision:\", precision_acost_ros)\n",
    "print(\"Recall:\", recall_grboost_ros)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_ros)\n",
    "print(classification_report(y_true=y_test_ros,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "AdaCost(learning_rate=0.05, n_estimators=100, random_state=100)\n",
      "AdaCost Classifier Metrics with RUS:\n",
      "Accuracy: 0.896551724137931\n",
      "Precision: 0.9057471264367816\n",
      "Recall: 0.9655172413793104\n",
      "Weighted F1 Score: 0.9656036643332468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.83      0.91      0.87        11\n",
      "           3       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.90        29\n",
      "   macro avg       0.91      0.90      0.90        29\n",
      "weighted avg       0.91      0.90      0.90        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ada_rus = AdaCost(algorithm = \"SAMME.R\",random_state = 100)\n",
    "cv = GridSearchCV(ada_rus,\n",
    "                  param_grid = {'learning_rate':[0.01,0.05,0.1,0.25,0.5,1],'n_estimators':[10,20,50,100,200]},\n",
    "                  verbose = 1, \n",
    "                  n_jobs = 1)\n",
    "cv.fit(X_train_rus,y_train_rus)\n",
    "cv.best_params_,cv.best_score_\n",
    "ada_cv = cv.best_estimator_\n",
    "print(cv.best_estimator_)\n",
    "y_pred_acost_rus = ada_cv.predict(X_test_rus)\n",
    "accuracy_acost_rus = accuracy_score(y_test_rus, y_pred_acost_rus)\n",
    "precision_acost_rus = precision_score(y_test_rus, y_pred_acost_rus, average='weighted')\n",
    "recall_acost_rus = recall_score(y_test_rus, y_pred_acost_rus, average='weighted')\n",
    "f1_acost_ros = f1_score(y_test_rus, y_pred_acost_rus, average='weighted')\n",
    "print(\"AdaCost Classifier Metrics with RUS:\")\n",
    "print(\"Accuracy:\", accuracy_acost_rus)\n",
    "print(\"Precision:\", precision_acost_rus)\n",
    "print(\"Recall:\", recall_grboost_rus)\n",
    "print(\"Weighted F1 Score:\", f1_grboost_rus)\n",
    "print(classification_report(y_true=y_test_rus,y_pred=y_pred_acost_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@K: 0.2414\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "k = 2  # Consider the top-2 predictions\n",
    "\n",
    "# Calculate MAP@K\n",
    "mapk_score = mapk(y_test_rus.to_numpy().T[0,:], ada_cv.predict_proba(X_test_rus), k)\n",
    "print(f\"MAP@K: {mapk_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
